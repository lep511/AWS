{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Captura de datos de cambios para DynamoDB Streams\n",
    "\n",
    "DynamoDB Streams captura una secuencia en orden cronológico de las modificaciones de los elementos en una tabla de DynamoDB y almacena esta información en un log durante un máximo de 24 horas. Las aplicaciones pueden obtener acceso a este registro y ver los elementos de datos tal y como se encontraban antes y después de la modificación, prácticamente en tiempo real.\n",
    "\n",
    "El cifrado en reposo cifra los datos en DynamoDB streams. Para obtener más información, consulte [Cifrado en reposo en DynamoDB](https://docs.aws.amazon.com/es_es/amazondynamodb/latest/developerguide/EncryptionAtRest.html).\n",
    "\n",
    "Una transmisión de DynamoDB es un flujo ordenado de información sobre los cambios que se realizan en los elementos de una tabla de DynamoDB. Cuando se habilita una transmisión en una tabla, DynamoDB obtiene información sobre cada modificación de los elementos de datos de esa tabla.\n",
    "\n",
    "Cada vez que una aplicación crea, actualiza o elimina elementos en la tabla, DynamoDB Streams escribe un registro de transmisión con los atributos de clave principal de los elementos modificados. Un registro de transmisión contiene información sobre una modificación de los datos de un solo elemento de una tabla de DynamoDB. Puede configurar la secuencia de tal forma que sus registros capturen información adicional; por ejemplo, las imágenes de \"antes\" y \"después\" de los elementos modificados.\n",
    "\n",
    "DynamoDB Streams ayuda a garantizar lo siguiente:\n",
    "\n",
    "* Cada registro de secuencia aparece una única vez en la secuencia.\n",
    "* Para cada elemento que se modifica de una tabla de DynamoDB, los registros de transmisión aparecen en el mismo orden en que se han realizado las modificaciones del elemento.\n",
    "\n",
    "DynamoDB Streams escribe los registros de transmisión prácticamente en tiempo real, para que pueda crear aplicaciones que consuman estas transmisiones y adopten medidas en función de su contenido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import pandas as pd\n",
    "import base64\n",
    "from spdynamodb import DynamoTable\n",
    "from datetime import datetime\n",
    "import json\n",
    "import time\n",
    "from decimal import Decimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Table name: FooBarTable            \n",
      "- Table arn: arn:aws:dynamodb:us-east-1:089715336747:table/FooBarTable            \n",
      "- Table creation: 2023-05-09 13:52:59            \n",
      "- [{'AttributeName': 'PK', 'KeyType': 'HASH'}, {'AttributeName': 'SK', 'KeyType': 'RANGE'}]            \n",
      "- [{'AttributeName': 'GSI1-PK', 'AttributeType': 'S'}, {'AttributeName': 'GSI1-SK', 'AttributeType': 'S'}, {'AttributeName': 'GSI2-SK', 'AttributeType': 'S'}, {'AttributeName': 'GSI3-SK', 'AttributeType': 'N'}, {'AttributeName': 'PK', 'AttributeType': 'S'}, {'AttributeName': 'SK', 'AttributeType': 'S'}, {'AttributeName': 'purchaseDate', 'AttributeType': 'S'}]            \n",
      "- Point-in-time recovery status: DISABLED  |  Delete protection: True\n"
     ]
    }
   ],
   "source": [
    "#dt = DynamoTable(profile_name='my-profile')\n",
    "dt=DynamoTable()\n",
    "try:\n",
    "    dt.select_table('FooBarTable')\n",
    "    print(dt)\n",
    "except:\n",
    "    dt.create_table(\n",
    "        table_name='FooBarTable',\n",
    "        partition_key='PK',\n",
    "        partition_key_type='S',\n",
    "        sort_key='SK',\n",
    "        sort_key_type='S',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.status_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.status_stream = 'ON'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.status_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.status_stream = 'KEYS_ONLY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.status_stream = 'OFF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.status_stream = 'KEYS_ONLY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.status_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.status_stream = 'KEYS_ONLY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.stream_arn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uso de Kinesis Data Streams para capturar cambios en DynamoDB\n",
    "\n",
    "Puede utilizar Amazon Kinesis Data Streams para capturar cambios en Amazon DynamoDB.\n",
    "\n",
    "Kinesis Data Streams captura modificaciones a nivel de elemento en cualquier tabla de DynamoDB y las replica en una secuencia de datos de Kinesis. Sus aplicaciones pueden acceder a este flujo de datos y ver los cambios a nivel de elemento casi en tiempo real. Puede capturar y almacenar continuamente terabytes de datos por hora. Puede aprovechar el tiempo de retención de datos más prolongado y, con la capacidad de distribución ramificada mejorada, puede llegar simultáneamente a dos o más aplicaciones descendentes. Otros beneficios incluyen una mayor transparencia de auditoría y seguridad.\n",
    "\n",
    "Kinesis Data Streams también le da acceso a Amazon Kinesis Data Firehose y Amazon Kinesis Data Analytics. Estos servicios pueden ayudarle a crear aplicaciones que alimenten paneles en tiempo real, generen alertas, apliquen precios y publicidad dinámicos y apliquen análisis de datos sofisticados y algoritmos de machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stream already exists\n"
     ]
    }
   ],
   "source": [
    "kinesis_client = boto3.client('kinesis', region_name='us-east-1')\n",
    "# Create kinesis data stream\n",
    "try:\n",
    "    response = kinesis_client.create_stream(\n",
    "        StreamName='FooBarStream',\n",
    "        ShardCount=1\n",
    "    )\n",
    "except ClientError as e:\n",
    "    if e.response['Error']['Code'] == 'ResourceInUseException':\n",
    "        print('Stream already exists')\n",
    "    else:\n",
    "        print(\"Unexpected error: %s\" % e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get kinesis data stream arn\n",
    "stream_arn = kinesis_client.describe_stream(StreamName='FooBarStream')['StreamDescription']['StreamARN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.table.meta.client.enable_kinesis_streaming_destination(\n",
    "    TableName=dt.table_name,\n",
    "    StreamArn=stream_arn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kinesis data stream destination is active\n"
     ]
    }
   ],
   "source": [
    "response = dt.table.meta.client.describe_kinesis_streaming_destination(\n",
    "    TableName=dt.table_name,\n",
    ")\n",
    "if response['KinesisDataStreamDestinations'][0]['DestinationStatus'] == 'ACTIVE':\n",
    "    print('Kinesis data stream destination is active')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '0730OHIGGPGICAF0FS0IUMC977VV4KQNSO5AEMVJF66Q9ASUAAJG',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'server': 'Server',\n",
       "   'date': 'Sat, 20 May 2023 19:38:40 GMT',\n",
       "   'content-type': 'application/x-amz-json-1.0',\n",
       "   'content-length': '2',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': '0730OHIGGPGICAF0FS0IUMC977VV4KQNSO5AEMVJF66Q9ASUAAJG',\n",
       "   'x-amz-crc32': '2745614147'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.table.update_item(\n",
    "    Key={\n",
    "        'PK': 'ORDER#1001',\n",
    "        'SK': 'ORDER#1001'\n",
    "    },\n",
    "    UpdateExpression='SET #attr = :val, #attr2 = :val2',\n",
    "    ExpressionAttributeNames={\n",
    "        '#attr': 'status',\n",
    "        '#attr2': 'totalItems'\n",
    "    },\n",
    "    ExpressionAttributeValues={\n",
    "        ':val': 'processing',\n",
    "        ':val2': 50\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records:  7\n"
     ]
    }
   ],
   "source": [
    "# Get records from kinisis data stream\n",
    "response = kinesis_client.describe_stream(StreamName='FooBarStream')\n",
    "shard_id = response['StreamDescription']['Shards'][0]['ShardId']\n",
    "shard_iterator = kinesis_client.get_shard_iterator(StreamName='FooBarStream', ShardId=shard_id, ShardIteratorType='TRIM_HORIZON')\n",
    "shard_iterator = shard_iterator['ShardIterator']\n",
    "response = kinesis_client.get_records(ShardIterator=shard_iterator, Limit=10)\n",
    "print(\"Number of records: \", len(response['Records']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_record(record):\n",
    "    data = json.loads(record['Data'].decode('utf-8'))\n",
    "    new_image = data['dynamodb']['NewImage']\n",
    "    old_image = data['dynamodb']['OldImage']\n",
    "    timestamp = record['ApproximateArrivalTimestamp'].strftime('%Y-%m-%d %H:%M:%S')\n",
    "    # Compare new and old images\t\n",
    "    if new_image != old_image:\n",
    "        # Get the item key\n",
    "        print('Timestamp: {}'.format(timestamp))\n",
    "        print('Item Key: {}'.format(new_image['PK']['S']))\n",
    "        print('Sort Key: {}'.format(new_image['SK']['S']))\n",
    "        # Get the item attributes\n",
    "        for key, value in new_image.items():\n",
    "            if key not in old_image or value != old_image[key]:\n",
    "                print('{}: {}  (New value)'.format(key, value))\n",
    "                print('{}: {}  (Old value)'.format(key, old_image[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 2023-05-20 16:38:40\n",
      "Item Key: ORDER#1001\n",
      "Sort Key: ORDER#1001\n",
      "status: {'S': 'processing'}  (New value)\n",
      "status: {'S': 'pending'}  (Old value)\n",
      "totalItems: {'N': '50'}  (New value)\n",
      "totalItems: {'N': '5'}  (Old value)\n"
     ]
    }
   ],
   "source": [
    "process_record(response['Records'][-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
