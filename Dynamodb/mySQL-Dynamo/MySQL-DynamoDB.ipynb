{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la terminal ejecute:\n",
    "\n",
    "* `bash start-sam.sh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Luego ejecute:\\n\")\n",
    "print(\">> sudo su\")\n",
    "print(\">> cd /var/lib/mysql-files/\")\n",
    "print(\">> ls -lrt\")\n",
    "print(\">> mysql -u dbuser -pPassword@123\")\n",
    "print(\"  > use imdb;\")\n",
    "print(\"  > show tables;\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Luego ejecute los comandos en el archivo `quer1.sql`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A título ilustrativo, a continuación se muestra un diagrama lógico que representa la relación entre varias tablas de origen que alojan el conjunto de datos IMDb.\n",
    "\n",
    "* La tabla `title_basics` contiene las películas publicadas en EE.UU. después del año 2000. tconst es una clave alfanumérica asignada de forma exclusiva a cada película.\n",
    "* `title_akas` contiene las regiones, los idiomas y los títulos de las películas publicadas. Es una relación 1:many con la tabla title_basics.\n",
    "* `title_ratings` tiene la clasificación de las películas y el recuento de votos. Para este ejercicio, podemos suponer que la información se actualiza con alta frecuencia tras el estreno de la película. Tiene una relación 1:1 con la tabla title_basics\n",
    "* `title_principals` contiene información sobre el reparto y el equipo. Tiene una relación 1:many con la tabla title_basics.\n",
    "* `title_crew` tiene información sobre el guionista y el director. Tiene una relación 1:1 con la tabla title_basics.\n",
    "* `name_basics` tiene información sobre el reparto y el equipo. Cada miembro tiene asignado un valor nconst único.\n",
    "<br><br>\n",
    "\n",
    "![Image](https://amazon-dynamodb-labs.com/images/migration31.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mysql-connector-python -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from decimal import Decimal\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to MySQL Server version  8.0.32\n",
      "Your connected to database:  ('imdb',)\n"
     ]
    }
   ],
   "source": [
    "host = \"3.231.154.66\"\n",
    "try:\n",
    "    connection_config_dict = {\n",
    "        'user': 'dbuser',\n",
    "        'password': 'Password@123',\n",
    "        'host': host,\n",
    "        'database': 'imdb',\n",
    "        'raise_on_warnings': True,\n",
    "        'use_pure': False,\n",
    "        'autocommit': True,\n",
    "        'pool_size': 32\n",
    "    }\n",
    "    connection = mysql.connector.connect(**connection_config_dict)\n",
    "\n",
    "    if connection.is_connected():\n",
    "        db_Info = connection.get_server_info()\n",
    "        print(\"Connected to MySQL Server version \", db_Info)\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"select database();\")\n",
    "        record = cursor.fetchone()\n",
    "        print(\"Your connected to database: \", record)\n",
    "        cursor = connection.cursor()\n",
    "        # global connection timeout arguments\n",
    "        global_connect_timeout = 'SET GLOBAL connect_timeout=655180'\n",
    "        global_wait_timeout = 'SET GLOBAL connect_timeout=655180'\n",
    "        global_interactive_timeout = 'SET GLOBAL connect_timeout=655180'\n",
    "\n",
    "        cursor.execute(global_connect_timeout)\n",
    "        cursor.execute(global_wait_timeout)\n",
    "        cursor.execute(global_interactive_timeout)\n",
    "\n",
    "        connection.commit()\n",
    "\n",
    "\n",
    "except Error as e:\n",
    "    print(\"Error while connecting to MySQL\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"use imdb;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('name_basics',), ('title_akas',), ('title_basics',), ('title_crew',), ('title_principals',), ('title_ratings',)]\n"
     ]
    }
   ],
   "source": [
    "cursor.execute(\"show tables;\")\n",
    "tables = cursor.fetchall()\n",
    "print(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"query1.sql\", \"r\") as query_sql:\n",
    "        query = query_sql.read()\n",
    "cursor.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total movies:  866763\n"
     ]
    }
   ],
   "source": [
    "cursor.execute(\"select count(*) from imdb.movies;\")\n",
    "total_movies = cursor.fetchone()\n",
    "print(\"Total movies: \", total_movies[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6238/3631294219.py:2: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  result_dataFrame = pd.read_sql(query, connection)\n"
     ]
    }
   ],
   "source": [
    "query = \"select * from imdb.movies\"\n",
    "result_dataFrame = pd.read_sql(query, connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySQL connection is closed\n"
     ]
    }
   ],
   "source": [
    "cursor.close()\n",
    "connection.close()\n",
    "print(\"MySQL connection is closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_dataFrame.to_csv('movies_compress.csv.gz', compression='gzip')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"movies_compress.csv.gz\")\n",
    "df = df.sort_values(by=['tconst']).reset_index().drop('Unnamed: 0', axis=1)\n",
    "df = df.where(pd.notnull(df), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dynamodb.Table(name='movies')\n"
     ]
    }
   ],
   "source": [
    "WITH_PROFILE = False\n",
    "region = 'us-east-1'\n",
    "table_name = 'movies'\n",
    "    \n",
    "if WITH_PROFILE:\n",
    "    profile = 'my-profile'\n",
    "    session = boto3.Session(profile_name=profile, region_name=region)\n",
    "    dynamodb = session.resource('dynamodb', region_name=region)\n",
    "else:\n",
    "    dynamodb = boto3.resource('dynamodb', region_name=region)\n",
    "\n",
    "try:\n",
    "    table = dynamodb.create_table(\n",
    "        TableName=table_name,\n",
    "        KeySchema=[\n",
    "            {\n",
    "                'AttributeName': 'id',\n",
    "                'KeyType': 'HASH'\n",
    "            },\n",
    "            {\n",
    "                'AttributeName': 'sk',\n",
    "                'KeyType': 'RANGE'\n",
    "            }\n",
    "        ],\n",
    "        AttributeDefinitions=[\n",
    "            {\n",
    "                'AttributeName': 'id',\n",
    "                'AttributeType': 'S'\n",
    "            },\n",
    "            {\n",
    "                'AttributeName': 'sk',\n",
    "                'AttributeType': 'S'\n",
    "            },\n",
    "        \n",
    "        ],\n",
    "        BillingMode=\"PAY_PER_REQUEST\"\n",
    "    )\n",
    "\n",
    "    # Wait until the table exists.\n",
    "    table.wait_until_exists()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "table = dynamodb.Table(table_name)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_json(item):\n",
    "    n_errors = []\n",
    "    js = {\n",
    "        \"id\": item[\"tconst\"],\n",
    "        \"sk\": item[\"nconst\"],\n",
    "    }\n",
    "    if item[\"ordering\"]: \n",
    "        try:\n",
    "            js[\"ordering\"] = int(item[\"ordering\"])\n",
    "        except:\n",
    "            n_errors.append(item)\n",
    "    if item[\"category\"]: \n",
    "        js[\"category\"] = item[\"category\"]\n",
    "    if item[\"genres\"]: \n",
    "        js[\"genres\"] = item[\"genres\"].split(\",\")\n",
    "    if item[\"job\"]: \n",
    "        js[\"job\"] = item[\"job\"]    \n",
    "    if item[\"characters\"]:\n",
    "        try:\n",
    "            js[\"characters\"] = json.loads(item[\"characters\"])\n",
    "        except:\n",
    "            n_errors.append(item)\n",
    "    if item[\"primaryName\"]:\n",
    "        js[\"primaryName\"] = item[\"primaryName\"]\n",
    "    if item[\"writers\"]: \n",
    "        js[\"writers\"] = item[\"writers\"].split(\",\")\n",
    "    return js, n_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(seconds):\n",
    "    seconds = seconds % (24 * 3600)\n",
    "    hour = seconds // 3600\n",
    "    seconds %= 3600\n",
    "    minutes = seconds // 60\n",
    "    seconds %= 60\n",
    "    \n",
    "    if hour > 1:\n",
    "        return \"{} hours, {} minutes and {} seconds remaining\".format(hour, minutes, seconds)\n",
    "    elif hour == 1:\n",
    "        return \"1 hour,{} minutes and {} seconds remaining\".format(minutes, seconds)\n",
    "    elif hour == 0 and minutes > 0:\n",
    "        return \"{} minutes and {} seconds remaining\".format(minutes, seconds)\n",
    "    else:\n",
    "        return \"{} seconds remaining\".format(seconds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "js_dir = \"json_data/\"\n",
    "error_dir = f\"{js_dir}/errors/\"\n",
    "process_dir = f\"{js_dir}/process/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass 1 from 5\n",
      "Pass 2 from 5\n",
      "Pass 3 from 5\n",
      "Pass 4 from 5\n",
      "Pass 5 from 5\n",
      "16555\n",
      "Found 0 errors.\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "n_count = 0\n",
    "n_end = 4000\n",
    "\n",
    "if len(df) % n_end == 0:\n",
    "    n_pass = int(len(df) / n_end)\n",
    "else:\n",
    "    n_pass = int(len(df) / n_end) + 1\n",
    "n_breake = False\n",
    "\n",
    "if os.path.isdir(js_dir):\n",
    "    actual_files = [f for f in os.listdir(js_dir) if os.path.isfile(os.path.join(js_dir,f))]\n",
    "    if len(actual_files) > 0:\n",
    "        raise Exception('Folder contain files.')  \n",
    "else:\n",
    "    os.mkdir(js_dir)\n",
    "    actual_files = []\n",
    "    \n",
    "for p in range(1, n_pass+1):\n",
    "    print(f\"Pass {p} from {n_pass}\")\n",
    "    if (n_count + n_end) > len(df):\n",
    "        n_c = n_count\n",
    "        n_end = abs(n_c - len(df))\n",
    "        print(n_count + n_end)\n",
    "    for i in range(n_end):\n",
    "        js, errors = generate_json(df.iloc[i+n_count])\n",
    "        data.append(js)\n",
    "    file_json = js_dir + \"/data-\" + str(p) + \".json\"\n",
    "    with open(file_json, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "       \n",
    "    data = []\n",
    "    n_count += n_end\n",
    "    \n",
    "print(\"Found {} errors.\".format(len(errors)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process: data-4.json  -  Remaing total: 5 files  -  1/5 session process files.\n",
      "-- 1 minutes and 48 seconds remaining --\n",
      "Process: data-2.json  -  Remaing total: 4 files  -  2/5 session process files.\n",
      "-- 1 minutes and 18 seconds remaining --\n",
      "Process: data-3.json  -  Remaing total: 3 files  -  3/5 session process files.\n",
      "-- 54 seconds remaining --\n",
      "Process: data-5.json  -  Remaing total: 2 files  -  4/5 session process files.\n",
      "-- 4 seconds remaining --\n",
      "Process: data-1.json  -  Remaing total: 1 files  -  5/5 session process files.\n",
      "-- 0 seconds remaining --\n",
      "No errors were found.\n"
     ]
    }
   ],
   "source": [
    "COUNT_SESSION = 5\n",
    "all_files = [f for f in os.listdir(js_dir) if os.path.isfile(os.path.join(js_dir,f))]\n",
    "process_files = []\n",
    "errors = []\n",
    "count_files_end = len(all_files)\n",
    "\n",
    "if COUNT_SESSION > len(all_files) or COUNT_SESSION < 0:\n",
    "    COUNT_SESSION = len(all_files)\n",
    "    int_count_session = COUNT_SESSION\n",
    "elif COUNT_SESSION == 0:\n",
    "    raise Exception('COUNT_SESSION cannot be 0')\n",
    "else:\n",
    "    int_count_session = COUNT_SESSION\n",
    "\n",
    "for file in all_files:\n",
    "    if COUNT_SESSION < 0:\n",
    "        print(f\"Process: {file}  -  Remaing total: {count_files_end} files.\")\n",
    "    else:\n",
    "        rest_cs = abs(int_count_session - COUNT_SESSION) + 1\n",
    "        print(f\"Process: {file}  -  Remaing total: {count_files_end} files  -  {rest_cs}/{int_count_session} session process files.\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    with open(js_dir + file) as json_data:\n",
    "        parsed = json.load(json_data, parse_float=Decimal)\n",
    "    with table.batch_writer() as writer:\n",
    "        for item in parsed:\n",
    "            try:\n",
    "                writer.put_item(Item=item)\n",
    "            except:\n",
    "                print(f\"[ERROR] In the item: {item}\")\n",
    "                errors.append(item)\n",
    "    \n",
    "    tot_sec = round(time.time() - start_time)\n",
    "    reamin_sec = convert(tot_sec * (COUNT_SESSION - 1))\n",
    "    print(\"-- {} --\".format(reamin_sec))\n",
    "    \n",
    "    if not os.path.isdir(process_dir):\n",
    "        os.mkdir(process_dir)\n",
    "    shutil.move(js_dir + file, process_dir + file)\n",
    "    \n",
    "    count_files_end -= 1\n",
    "    COUNT_SESSION -= 1\n",
    "    if COUNT_SESSION == 0:\n",
    "        break\n",
    "   \n",
    "if len(errors) != 0:\n",
    "    print(\"Found {} error/s.\".format(len(errors)))\n",
    "    if not os.path.isdir(error_dir):\n",
    "        os.mkdir(error_dir)\n",
    "    json_object = json.dumps(errors, indent=4)\n",
    "    now = datetime.now()\n",
    "    file_name = \"errors-\" + now.strftime(\"%d-%m-%Y-\") + now.strftime(\"%H%M%S\") + \".json\"\n",
    "    \n",
    "    # Writing to sample.json\n",
    "    with open(error_dir + \"/\" + file_name, \"w\") as outfile:\n",
    "        outfile.write(json_object)\n",
    "else:\n",
    "    print(\"No errors were found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c9cdd2fa3b32da9704bd8048bdba085d67219855a318f4adc7f095bb5cfa603b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
