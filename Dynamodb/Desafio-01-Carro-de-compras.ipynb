{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desafío del carro de la compra\n",
    "\n",
    "Una tienda online le ha pedido que diseñe su capa de almacenamiento de datos y su(s) tabla(s) NoSQL. El sitio web sirve a los clientes y a los productos que ven, guardan y compran. El tráfico del sitio web es actualmente bajo, pero quieren ser capaces de servir a millones de clientes simultáneos.\n",
    "\n",
    "* Los clientes interactúan con productos que pueden estar `ACTIVE`, `SAVED` o `PURCHASED`. Una vez que son `PURCHASED` se les asigna un OrderId.\n",
    "* Los productos tienen los siguientes atributos: AccountID, Status (ACTIVE, SAVED, or PURCHASED), CreateTimestamp, and ItemSKU (El tamaño total del artículo es <= 1 KB).\n",
    "* Cuando un cliente abre la aplicación de la tienda, ve los productos activos en su cesta, que están organizados por los añadidos más recientemente.\n",
    "* Los usuarios pueden ver los productos que han guardado para más tarde, organizados por los últimos guardados.\n",
    "* Los usuarios pueden ver los productos que han comprado, organizados por los últimos comprados.\n",
    "* Los equipos de producto tienen la capacidad de consultar regularmente a todos los clientes para identificar a las personas que tienen un producto específico en su cuenta que está `ACTIVE`, `SAVED` o `PURCHASED`.\n",
    "* El equipo de Business Intelligence necesita ejecutar una serie de consultas ad hoc complejas en el conjunto de datos para crear informes semanales y mensuales.\n",
    "\n",
    "Construir un Modelo de Datos NoSQL para cumplir con el componente OLTP (OnLine Transaction Processing) de la carga de trabajo. ¿Cómo cumpliría los requisitos del equipo de BI?\n",
    "\n",
    "#### ¿Cuáles son los patrones de acceso?\n",
    "\n",
    "**Los patrones de acceso en el escenario son:**\n",
    "\n",
    "* Insertar y actualizar artículos colocados en un carro por los usuarios.\n",
    "* Devuelve los artículos relacionados con un usuario (AccountID), ordenados por CreateTimestamp y asignados a un estado específico.\n",
    "* Devolución de artículos a través del usuario por ItemSKU, ordenados por CreateTimestamp, y con alcance a un Estado específico.\n",
    "* Consultas ad hoc fuera de línea para el equipo de Business Intelligence.\n",
    "\n",
    "**Identifique posibles claves de partición para cumplir el patrón de acceso primario:**\n",
    "\n",
    "* ¿Qué atributo de ítem escala en volumen junto con un mayor acceso?\n",
    "* ¿Cuál es la organización natural de los elementos de datos relacionados (para devolver los elementos recopilados en relación con los patrones de acceso anteriores)?\n",
    "* Considere la dimensión del acceso: tanto lecturas como escrituras.\n",
    "\n",
    "**Al determinar cómo organizar los elementos relacionados con el patrón de acceso principal:**\n",
    "\n",
    "* ¿Qué organización debe escribirse para devolver los elementos ordenados (ordenar por)?\n",
    "* ¿Cuál es la jerarquía de las relaciones (de más general a más específica)?\n",
    "\n",
    "**Cumplimiento de los patrones de acceso segundo, tercero y cuarto:**\n",
    "\n",
    "* Los patrones de acceso segundo y tercero son patrones de acceso OLTP y pueden modelarse directamente en DynamoDB.\n",
    "* El cuarto patrón de acceso es OLAP y no necesita cumplirse directamente en DynamoDB, o en su solución para el caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import random\n",
    "from botocore.exceptions import ClientError\n",
    "import pandas as pd\n",
    "from spdynamodb import DynamoTable\n",
    "import json\n",
    "import time\n",
    "from decimal import Decimal\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table created successfully!\n"
     ]
    }
   ],
   "source": [
    "#dt = DynamoTable(profile_name='089715336747_DynamoAttributes')\n",
    "dt=DynamoTable()\n",
    "try:\n",
    "    dt.select_table('CustomerPurchases')\n",
    "    print(dt)\n",
    "except:\n",
    "    dt.create_table(\n",
    "        table_name='CustomerPurchases',\n",
    "        partition_key='PK',\n",
    "        partition_key_type='S',\n",
    "        sort_key='SK',\n",
    "        sort_key_type='S',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Global Secondary Index\n",
    "dt.create_global_secondary_index(\n",
    "    att_name=\"GSI1PK\",\n",
    "    att_type=\"S\",\n",
    "    sort_index=\"GSI1SK\",\n",
    "    sort_type=\"S\",\n",
    "    i_name=\"GSI1\",\n",
    "    proj_type=[\"ItemSKU\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global secondary index is being created, this may take a few minutes...\n",
      "Global secondary index created. Time elapsed: 9.05 minute\n"
     ]
    }
   ],
   "source": [
    "status = dt.check_status_gsi()\n",
    "if status == 'CREATING':\n",
    "    print(\"Global secondary index is being created, this may take a few minutes...\")\n",
    "    start = time.time()\n",
    "    while status == 'CREATING':\n",
    "        status = dt.check_status_gsi()\n",
    "        time.sleep(30)\n",
    "end = time.time()\n",
    "minute = (end - start) / 60\n",
    "print(\"Global secondary index created. Time elapsed: {0:.2f} minute\".format(minute))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded into DynamoDB table.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('retail_cart_chall.csv')\n",
    "nx = df.ItemSKU.to_list()\n",
    "new_dt = []\n",
    "for elem in nx:\n",
    "    new_dt.append(json.loads(elem, parse_float=Decimal))\n",
    "df['ItemSKU'] = new_dt\n",
    "dt.batch_pandas(df)\n",
    "print(\"Data successfully loaded into DynamoDB table.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agregar elementos al carro de compras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_date = datetime.utcnow().isoformat().split('.')[0]+'Z'\n",
    "\n",
    "dt.add_item(\n",
    "    item={\n",
    "        \"PK\": \"12856333\",\n",
    "        \"SK\": \"12856333#ACTIVE#P-8995\",\n",
    "        \"AccountId\": \"12856333\",\n",
    "        \"CreateTimestamp\": iso_date,\n",
    "        \"GSI1PK\": \"12856333#ACTIVE\",\n",
    "        \"GSI1SK\": iso_date,\n",
    "        \"ItemSKU\": {\"ProductId\":\"P-8995\",\"Quantity\": 2, \"Price\": Decimal('199.99'), \"Category\": \"Electronics\"},\n",
    "        \"Status\": \"ACTIVE\"\n",
    "    }\n",
    ") \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_date = datetime.utcnow().isoformat().split('.')[0]+'Z'\n",
    "\n",
    "dt.add_item(\n",
    "    item={\n",
    "        \"PK\": \"12856333\",\n",
    "        \"SK\": \"12856333#ACTIVE#P-8998\",\n",
    "        \"AccountId\": \"12856333\",\n",
    "        \"CreateTimestamp\": iso_date,\n",
    "        \"GSI1PK\": \"12856333#ACTIVE\",\n",
    "        \"GSI1SK\": iso_date,\n",
    "        \"ItemSKU\": {\"ProductId\":\"P-8998\",\"Quantity\": 1, \"Price\": Decimal('499.99'), \"Category\": \"Electronics\"},\n",
    "        \"Status\": \"ACTIVE\"\n",
    "    }\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_date = datetime.utcnow().isoformat().split('.')[0]+'Z'\n",
    "\n",
    "dt.add_item(\n",
    "    item={\n",
    "        \"PK\": \"12856333\",\n",
    "        \"SK\": \"12856333#ACTIVE#P-10599\",\n",
    "        \"AccountId\": \"12856333\",\n",
    "        \"CreateTimestamp\": iso_date,\n",
    "        \"GSI1PK\": \"12856333#ACTIVE\",\n",
    "        \"GSI1SK\": iso_date,\n",
    "        \"ItemSKU\": {\"ProductId\":\"P-10599\",\"Quantity\": 1, \"Price\": Decimal('699.99'), \"Category\": \"TV\"},\n",
    "        \"Status\": \"ACTIVE\"\n",
    "    }\n",
    ") \n",
    "   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtener todos los elementos del carrito:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = dt.query(\"12856333\", \"12856333#ACTIVE*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elem_total(elem):\n",
    "    total = 0\n",
    "    for item in elem:\n",
    "        total += item['ItemSKU']['Quantity']\n",
    "    return total\n",
    "\n",
    "def calc_total(items):\n",
    "    total = 0\n",
    "    for item in items:\n",
    "        total += item['ItemSKU']['Price'] * item['ItemSKU']['Quantity']\n",
    "    return total\n",
    "\n",
    "def get_category(items):\n",
    "    category = []\n",
    "    for item in items:\n",
    "        category.append(item['ItemSKU']['Category'])\n",
    "    return list(set(category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de elementos: 4\n",
      "Total de la compra: 1599.96 USD\n",
      "Categorias de los productos: ['TV', 'Electronics']\n"
     ]
    }
   ],
   "source": [
    "print(\"Cantidad de elementos:\", elem_total(response))\n",
    "print(\"Total de la compra:\", calc_total(response), \"USD\")\n",
    "print(\"Categorias de los productos:\", get_category(response))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realizar la compra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate unique id\n",
    "sample_num = random.randint(100000, 999999)\n",
    "token = f\"O-{sample_num}\"\n",
    "dynamo_client = boto3.client('dynamodb', region_name='us-east-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_items = []\n",
    "iso_date = datetime.utcnow().isoformat().split('.')[0]+'Z'\n",
    "\n",
    "for item in response:\n",
    "    action_items.append(\n",
    "        {\n",
    "            \"Put\":\n",
    "                {\n",
    "                    \"TableName\": dt.table_name,\n",
    "                    \"Item\": {\n",
    "                        \"PK\": {\"S\": item['PK']},\n",
    "                        \"SK\": {\"S\": item['PK']+\"#PURCHASED\"+\"#\"+token+\"#\"+item['ItemSKU']['ProductId']},\n",
    "                        \"AccountId\": {\"S\": item['AccountId']},\n",
    "                        \"CreateTimestamp\": {\"S\": iso_date},\n",
    "                        \"GSI1PK\": {\"S\": item['PK']+\"#PURCHASED\"},\n",
    "                        \"GSI1SK\": {\"S\": iso_date},\n",
    "                        \"ItemSKU\": {\"M\": {\n",
    "                            \"ProductId\": {\"S\": item['ItemSKU']['ProductId']},\n",
    "                            \"Quantity\": {\"N\": str(item['ItemSKU']['Quantity'])},\n",
    "                            \"Price\": {\"N\": str(item['ItemSKU']['Price'])},\n",
    "                            \"Category\": {\"S\": item['ItemSKU']['Category']}\n",
    "                            }\n",
    "                        },\n",
    "                        \"Status\": {\"S\": \"PURCHASED\"},\n",
    "                        \"OrderId\": {\"S\": token}\n",
    "                    }\n",
    "                }\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in response:\n",
    "    action_items.append(\n",
    "        {\n",
    "            \"Delete\":\n",
    "                {\n",
    "                    \"Key\": {\"PK\": {\"S\": item['PK']}, \"SK\": {\"S\": item['SK']}},\n",
    "                    \"TableName\": dt.table_name\n",
    "                }\n",
    "        }\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transaction successful.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    dynamo_client.transact_write_items(\n",
    "        TransactItems=action_items,\n",
    "        ClientRequestToken=token\n",
    "    )\n",
    "    print(\"Transaction successful.\")\n",
    "except ClientError as e:\n",
    "    print(f\"Error: {e.response['Error']['Message']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-10599 1 699.99 TV\n",
      "P-8995 2 199.99 Electronics\n",
      "P-8998 1 499.99 Electronics\n"
     ]
    }
   ],
   "source": [
    "response = dt.query(\"12856333\", \"12856333#PURCHASED#\"+token+\"*\")\n",
    "if response:\n",
    "    for item in response:\n",
    "        print(item['ItemSKU']['ProductId'], item['ItemSKU']['Quantity'], item['ItemSKU']['Price'], item['ItemSKU']['Category'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar elementos en favoritos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_date = datetime.utcnow().isoformat().split('.')[0]+'Z'\n",
    "\n",
    "dt.add_item(\n",
    "    item={\n",
    "        \"PK\": \"12856333\",\n",
    "        \"SK\": \"12856333#SAVED#P-8997\",\n",
    "        \"AccountId\": \"12856333\",\n",
    "        \"CreateTimestamp\": iso_date,\n",
    "        \"GSI1PK\": \"12856333#SAVED\",\n",
    "        \"GSI1SK\": iso_date,\n",
    "        \"ItemSKU\": {\"ProductId\":\"P-8997\", \"Category\": \"TV\"},\n",
    "        \"Status\": \"SAVED\"\n",
    "    }\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_date = datetime.utcnow().isoformat().split('.')[0]+'Z'\n",
    "\n",
    "dt.add_item(\n",
    "    item={\n",
    "        \"PK\": \"12856333\",\n",
    "        \"SK\": \"12856333#SAVED#P-8995\",\n",
    "        \"AccountId\": \"12856333\",\n",
    "        \"CreateTimestamp\": iso_date,\n",
    "        \"GSI1PK\": \"12856333#SAVED\",\n",
    "        \"GSI1SK\": iso_date,\n",
    "        \"ItemSKU\": {\"ProductId\":\"P-8995\", \"Category\": \"Electronics\"},\n",
    "        \"Status\": \"SAVED\"\n",
    "    }\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consumed Capacity: 0.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'CreateTimestamp': '2023-06-16T14:57:54Z',\n",
       "  'GSI1PK': '12856333#SAVED',\n",
       "  'AccountId': '12856333',\n",
       "  'ItemSKU': {'ProductId': 'P-8995', 'Category': 'Electronics'},\n",
       "  'SK': '12856333#SAVED#P-8995',\n",
       "  'Status': 'SAVED',\n",
       "  'GSI1SK': '2023-06-16T14:57:54Z',\n",
       "  'PK': '12856333'},\n",
       " {'CreateTimestamp': '2023-06-16T14:57:52Z',\n",
       "  'GSI1PK': '12856333#SAVED',\n",
       "  'AccountId': '12856333',\n",
       "  'ItemSKU': {'ProductId': 'P-8997', 'Category': 'TV'},\n",
       "  'SK': '12856333#SAVED#P-8997',\n",
       "  'Status': 'SAVED',\n",
       "  'GSI1SK': '2023-06-16T14:57:52Z',\n",
       "  'PK': '12856333'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtener los productos guardados\n",
    "dt.query(\"12856333\", \"12856333#SAVED*\", consumed_capacity=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtener todos los elementos comprados por un usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = dt.query(\"12856333\", \"12856333#PURCHASED*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-10599 1 699.99 2023-06-15T15:19:38Z\n",
      "P-8995 2 199.99 2023-06-15T15:19:38Z\n",
      "P-8998 1 499.99 2023-06-15T15:19:38Z\n",
      "P-10599 1 699.99 2023-06-14T23:29:19Z\n",
      "P-8995 2 199.99 2023-06-14T23:29:19Z\n",
      "P-8998 1 499.99 2023-06-14T23:29:19Z\n"
     ]
    }
   ],
   "source": [
    "for item in response:\n",
    "    print(item['ItemSKU']['ProductId'], item['ItemSKU']['Quantity'], item['ItemSKU']['Price'], item['CreateTimestamp'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cómo realizar análisis avanzados y crear visualizaciones de sus datos de Amazon DynamoDB mediante Amazon Athena\n",
    "\n",
    "Puede obtener un enorme valor analítico de miles de millones de elementos y millones de solicitudes por segundo en su servicio de Amazon DynamoDB. Sin embargo, necesita exportar sus datos para obtener ese valor analítico. Copiar los datos de una tabla de DynamoDB a una plataforma de análisis le permite extraer información detallada. Para lograrlo, creemos que una canalización de big data bien diseñada ayuda a separar el procesamiento transaccional de los análisis. Esta publicación del blog muestra cómo crear una canalización de big data que transfiere los datos de la tabla de DynamoDB a Amazon S3. Esto le ayuda a realizar análisis avanzados mediante Amazon Athena, un servicio de consulta Presto totalmente administrado, y también le ayuda a crear visualizaciones y análisis ad hoc mediante Amazon QuickSight.\n",
    "\n",
    "La mayoría de las aplicaciones de big data desacopladas tienen una canalización común que separa el almacenamiento de la informática, lo que le permite aprovechar las nuevas tecnologías de procesamiento a medida que llegan. El desacoplamiento permite el aprovisionamiento elástico de recursos informáticos para varios motores de análisis sin afectar a la durabilidad de los datos. También es posible que desee diseñar su canalización de modo que las etapas de almacenamiento y procesamiento se repitan para dar forma a los datos en un formato que las aplicaciones posteriores puedan consumir rápidamente.\n",
    "\n",
    "Tres características principales influyen en el diseño de una canalización de big data:\n",
    "\n",
    "* Latencia de la canalización general: ¿cuánto tiempo se necesita para pasar de los datos a la información? ¿Milisegundos, minutos o días?\n",
    "* Rendimiento de los datos: ¿cuántos datos hay que ingerir y procesar? ¿Se trata de gigabytes, terabytes o petabytes?\n",
    "* Coste: ¿cuál es el presupuesto previsto para su aplicación? La opción más rentable de AWS suele ser la correcta.\n",
    "\n",
    "Otras consideraciones clave a la hora de diseñar su canalización de big data son la estructura de los datos, los patrones de acceso, la temperatura de los datos, la disponibilidad y durabilidad, y si el servicio está totalmente administrado. Utilizar las herramientas adecuadas para el trabajo en función de estas características es clave para una canalización de big data bien diseñada."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejecute el siguiente comando en la terminal**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "cd .SAM/RetailCartChallenge/\n",
    "sam build\n",
    "sam deploy --guided --capabilities CAPABILITY_NAMED_IAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kinesis_arn = 'arn:aws:kinesis:us-east-1:688504933740:stream/sam-app-kinesis-stream-51568'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DynamoDB table associated with Kinesis Data Stream successfully.\n"
     ]
    }
   ],
   "source": [
    "dynamo_client = boto3.client('dynamodb', region_name='us-east-1')\n",
    "# Asociate dynamodb table with kinesis data stream\n",
    "try:\n",
    "    response = dynamo_client.enable_kinesis_streaming_destination(\n",
    "        TableName=dt.table_name,\n",
    "        StreamArn=kinesis_arn\n",
    "    )\n",
    "    print(\"DynamoDB table associated with Kinesis Data Stream successfully.\")\n",
    "except ClientError as e:\n",
    "    print(f\"Error: {e.response['Error']['Message']}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate massive data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION TO GENERATE DATA\n",
    "def generate_data(user_data=10, generator=100):\n",
    "    iso_date = datetime.utcnow().isoformat().split('.')[0]+'Z'\n",
    "    pk = []\n",
    "    sk = []\n",
    "    account_list = []\n",
    "    create_timestamp = []\n",
    "    gsi1pk = []\n",
    "    gsi1sk = []\n",
    "    item_sku = []\n",
    "    status_list = []\n",
    "    print(\"Generating data...\")\n",
    "    for i in range(1, user_data):\n",
    "        account = str(random.randint(10000000, 99999999))\n",
    "        for m in range(1, generator):\n",
    "            price = num = round(random.uniform(1, 3500), 2)\n",
    "            product = \"P-\" + str(random.randint(1000, 9999))\n",
    "            token = \"O-\" + str(random.randint(100000, 999999))\n",
    "            status = random.choice([\"ACTIVE\", \"SAVED\", \"PURCHASED\", \"PURCHASED\", \"PURCHASED\"])\n",
    "            category = random.choice([\"Electronics\", \"TV\", \"Smartphone\", \"Laptop\", \"Tablet\"])\n",
    "            quantity = random.choice([1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 5])\n",
    "            \n",
    "            if status == \"ACTIVE\":\n",
    "                pk.append(account)\n",
    "                sk.append(f\"{account}#ACTIVE#{product}\")\n",
    "                account_list.append(account)\n",
    "                create_timestamp.append(iso_date)\n",
    "                gsi1pk.append(f\"{account}#ACTIVE\")\n",
    "                gsi1sk.append(iso_date)\n",
    "                item_sku.append({\"ProductId\":product, \"Quantity\": quantity, \"Price\": price, \"Category\": category})\n",
    "                status_list.append(\"ACTIVE\")\n",
    "\n",
    "            elif status == \"SAVED\":\n",
    "                pk.append(account)\n",
    "                sk.append(f\"{account}#SAVED#{product}\")\n",
    "                account_list.append(account)\n",
    "                create_timestamp.append(iso_date)\n",
    "                gsi1pk.append(f\"{account}#SAVED\")\n",
    "                gsi1sk.append(iso_date)\n",
    "                item_sku.append({\"ProductId\":product, \"Category\": category})\n",
    "                status_list.append(\"SAVED\")\n",
    "\n",
    "            elif status == \"PURCHASED\":\n",
    "                pk.append(account)\n",
    "                sk.append(f\"{account}#PURCHASED#{token}#{product}\")\n",
    "                account_list.append(account)\n",
    "                create_timestamp.append(iso_date)\n",
    "                gsi1pk.append(f\"{account}#PURCHASED\")\n",
    "                gsi1sk.append(iso_date)\n",
    "                item_sku.append({\"ProductId\":product, \"Quantity\": quantity, \"Price\": price, \"Category\": category})\n",
    "                status_list.append(\"PURCHASED\")\n",
    "            \n",
    "    df_main = pd.DataFrame(\n",
    "        {\"PK\": pk,\n",
    "         \"SK\": sk,\n",
    "         \"AccountId\": account_list,\n",
    "         \"CreateTimestamp\": create_timestamp,\n",
    "         \"GSI1PK\": gsi1pk,\n",
    "         \"GSI1SK\": gsi1sk,\n",
    "         \"ItemSKU\": item_sku,\n",
    "         \"Status\": status_list\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    total = user_data * generator\n",
    "    print(f\"{total} items.\")\n",
    "    return df_main\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "1000 items.\n"
     ]
    }
   ],
   "source": [
    "df = generate_data(user_data=10, generator=100)\n",
    "try:\n",
    "    dt.batch_pandas(df)\n",
    "except:\n",
    "    df = generate_data(user_data=10, generator=50)\n",
    "    dt.batch_pandas(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
