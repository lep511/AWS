{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Almacenamiento\n",
    "\n",
    "Muchas industrias han puesto un gran énfasis en las tecnologías de almacenamiento de datos en la nube para ayudar a facilitar la creciente demanda de datos. Hay muchas opciones disponibles para el almacenamiento de datos que se adaptan a sus necesidades, con una escala aparentemente infinita. Incluso con muchas nuevas opciones de almacenamiento disponibles en la nube, Amazon S3 sigue siendo un bloque de construcción potente y fundamental para muchos casos de uso. Es increíble pensar que se lanzó hace más de 15 años. Con el tiempo, se han añadido muchas características y se han lanzado nuevos servicios de almacenamiento. Existen múltiples opciones de almacenamiento para satisfacer los requisitos de seguridad (por ejemplo, el cifrado del servicio de gestión de claves [**KMS**]) y reducir los costes (por ejemplo, *S3 Intelligent-Tiering*). Garantizar la seguridad y la disponibilidad de los datos es un reto al que se enfrentan todos los desarrolladores y arquitectos.\n",
    "\n",
    "Los servicios de almacenamiento disponibles en AWS permiten la integración con otros servicios de AWS para proporcionar formas a los desarrolladores y arquitectos de aplicaciones que se integran con muchos servicios de AWS. Estos servicios también pueden utilizarse para sustituir los sistemas de almacenamiento heredados que se ejecutan y operan con entornos on-premise. Por ejemplo:\n",
    "\n",
    "* S3 puede utilizarse para invocar automáticamente funciones Lambda en operaciones de objetos como la carga.\n",
    "\n",
    "* EFS puede utilizarse con EC2 para sustituir los sistemas de archivos compartidos existentes proporcionados por los servidores del sistema de archivos de red (NFS).\n",
    "\n",
    "* FSx para Windows puede utilizarse para sustituir a los servidores de archivos basados en Windows para sus cargas de trabajo de EC2.\n",
    "\n",
    "* EBS sustituye a los objetivos de Canal de Fibra y de Interfaz de Sistemas de Computadoras Pequeñas de Internet (iSCSI) proporcionando dispositivos de bloque, y ofrece muchas opciones de rendimiento para satisfacer los requisitos de rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uso de las políticas del ciclo de vida de S3 para reducir los costes de almacenamiento\n",
    "\n",
    "#### Problema\n",
    "Necesita trasladar los objetos a los que se accede con poca frecuencia a un nivel de almacenamiento más rentable sin que ello afecte al rendimiento o añada una sobrecarga operativa.\n",
    "\n",
    "#### Solución\n",
    "Cree una regla del ciclo de vida de S3 para realizar la transición de los objetos a la clase de almacenamiento de acceso infrecuente (IA) de S3 después de un período de tiempo predefinido de 30 días. A continuación, aplique esta política de ciclo de vida a su cubo de S3.\n",
    "\n",
    "<img src=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/images/lifecycle-transitions-v3.png\" width=\"900\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import random\n",
    "from pprint import pprint \n",
    "\n",
    "region_aws = 'us-east-1'\n",
    "\n",
    "ec2 = boto3.resource('ec2', region_name=region_aws)\n",
    "ec2_client = boto3.client('ec2', region_name=region_aws)\n",
    "s3 = boto3.resource('s3')\n",
    "s3_client = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket name: cookbook-86954\n"
     ]
    }
   ],
   "source": [
    "# Create a bucket\n",
    "bucket_name = 'cookbook-{}'.format(random.randint(10000, 1000000))\n",
    "bucket = s3.create_bucket(Bucket=bucket_name)\n",
    "print(\"Bucket name: {}\".format(bucket_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por defecto cuando creamos un bucket, las opciones de **Block all public access** (Bloquear todo el acceso público) están desactivadas por defecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = s3_client.put_public_access_block(\n",
    "        Bucket=bucket_name,\n",
    "        PublicAccessBlockConfiguration={\n",
    "            'BlockPublicAcls': True,\n",
    "            'IgnorePublicAcls': True,\n",
    "            'BlockPublicPolicy': True,\n",
    "            'RestrictPublicBuckets': True\n",
    "        }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cree un ciclo de vida que aplicará a su bucket de S3:\n",
    "\n",
    "Cuando añade una configuración de S3 Lifecycle a un bucket, por lo general se produce un cierto desfase antes de que una configuración de ciclo de vida nueva o actualizada se propague totalmente a todos los sistemas de Amazon S3. Habrá un retraso de algunos minutos antes de que la configuración entre en vigor completamente. Este retraso también se puede producir cuando elimina una configuración de S3 Lifecycle.\n",
    "\n",
    "**NOTA:** Cada bucket tiene 1 configuración de ciclo de vida, que puede tener hasta 1000 reglas, *put_bucket_lifecycle_configuration* crea una nueva configuración de ciclo de vida para el cubo o **sustituye** una configuración de ciclo de vida existente. Si quieres actualizar la configuración del ciclo de vida, tienes que usar *get_bucket_lifecycle_configuration* para recuperar las reglas existentes, modificarlas y luego usar *put_bucket_lifecycle_configuration* para sobrescribir la configuración existente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a json data:\n",
    "json_data = {\n",
    "    \"Rules\": [\n",
    "        {\n",
    "            \"ID\": \"Move all objects to Standard Infrequently Access\",\n",
    "            \"Filter\": {\n",
    "                \"Prefix\": \"\"\n",
    "            },\n",
    "            \"Status\": \"Enabled\",\n",
    "            \"Transitions\": [\n",
    "                {\n",
    "                    \"Days\": 30,                   \n",
    "                    \"StorageClass\": \"STANDARD_IA\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifecycle configuration applied.\n"
     ]
    }
   ],
   "source": [
    "# Apply the Lifecycle rule configuration:\n",
    "response = s3_client.put_bucket_lifecycle_configuration(\n",
    "    Bucket=bucket_name,\n",
    "    LifecycleConfiguration=json_data\n",
    ")\n",
    "\n",
    "if response['ResponseMetadata']['HTTPStatusCode'] == 200:\n",
    "    print(\"Lifecycle configuration applied.\")\n",
    "else:\n",
    "    print(\"ERROR: Something went wrong.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Una regla de ciclo de vida ayuda a automatizar la transición a una clase de almacenamiento diferente para algunos o todos los objetos de un cubo (los prefijos, las etiquetas y los nombres de los objetos pueden utilizarse como filtros para las reglas de ciclo de vida). Para obtener una lista completa de las capacidades de las reglas del ciclo de vida, consulte la documentación.\n",
    "\n",
    "* Cuando añade una configuración de ciclo de vida a un bucket, las reglas de configuración se aplican a los objetos existentes y a los objetos que añade posteriormente. Por ejemplo, si hoy añade una regla de configuración de Lifecycle con una acción de vencimiento que causa que objetos con un prefijo específico expiren 30 días después de la creación, Amazon S3 pondrá en cola de eliminación cualquier objeto existente con más de 30 días de antigüedad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Controles de validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"ID\": \"Move all objects to Standard Infrequently Access\",\n",
      "        \"Prefix\": \"\",\n",
      "        \"Status\": \"Enabled\",\n",
      "        \"Transitions\": [\n",
      "            {\n",
      "                \"Days\": 30,\n",
      "                \"StorageClass\": \"STANDARD_IA\"\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Get the Lifecycle configuration for your bucket:\n",
    "response = s3_client.get_bucket_lifecycle_configuration(\n",
    "    Bucket=bucket_name\n",
    ")\n",
    "\n",
    "print(json.dumps(response['Rules'], indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload a object to S3:\n",
    "response = s3.Object(bucket_name, 'object_to_delte.json').put(Body=open('ip-ranges.json', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the storage class for the object:\n",
    "response = s3_client.list_objects(\n",
    "    Bucket=bucket_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ETag': '\"a4c4f220536a3a2bbfb53e6772039d1d\"',\n",
      " 'Key': 'object_to_delte.json',\n",
      " 'LastModified': datetime.datetime(2022, 10, 15, 14, 30, 10, tzinfo=tzutc()),\n",
      " 'Owner': {'DisplayName': 'lab+LabServices-Prod-5828',\n",
      "           'ID': '458f686c07dc2a102045f8b9923f246690c2ba35949449f75b715f1020bd5116'},\n",
      " 'Size': 1348061,\n",
      " 'StorageClass': 'STANDARD'}\n"
     ]
    }
   ],
   "source": [
    "pprint(response['Contents'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de 30 días verá que la clase de almacenamiento del objeto es STANDARD_IA tras ejecutar el mismo comando.\n",
    "\n",
    "**TIP:** \"Días\" en la acción de transición debe ser mayor o igual a 30 para StorageClass STANDARD_IA. Otras clases de almacenamiento permiten tiempos de transición más cortos para satisfacer sus necesidades. Para obtener una lista de todas las clases de almacenamiento disponibles con tiempos de transición para las reglas del ciclo de vida, consulte el [documento de soporte](https://oreil.ly/6jPLh)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discusión\n",
    "Cuando se cargan objetos en un bucket de S3, si no se especifica la clase de almacenamiento, se utiliza la clase de almacenamiento estándar por defecto. Amazon S3 dispone de varias clases de almacenamiento que pueden ser más rentables para el almacenamiento a largo plazo, al tiempo que se adaptan a sus requisitos de rendimiento y resistencia. Si no puede cambiar su aplicación para especificar los niveles de almacenamiento para las cargas de objetos, las reglas del ciclo de vida pueden ayudar a automatizar la transición a la clase de almacenamiento que desee. Las reglas del ciclo de vida pueden aplicarse a algunos o a todos los objetos dentro de un cubo con un filtro.\n",
    "\n",
    "Como su nombre indica, S3 Infrequent Access es una clase de almacenamiento que proporciona un coste reducido (en comparación con la clase de almacenamiento S3 Standard) para los datos almacenados para los objetos a los que rara vez se accede. Esto proporciona el mismo nivel de redundancia para sus datos dentro de una Región por un coste reducido, pero el coste asociado al acceso a los objetos es ligeramente superior. Si sus patrones de acceso a los datos son impredecibles, y todavía desea optimizar su almacenamiento en S3 para el costo, el rendimiento y la capacidad de recuperación, eche un vistazo a S3 Intelligent-Tiering en la siguiente receta.\n",
    "\n",
    "#### Reto 1\n",
    "Configure la regla del ciclo de vida para que se aplique sólo a los objetos basados en etiquetas de nivel de objeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de reglas actuales: 2\n"
     ]
    }
   ],
   "source": [
    "# Get the Lifecycle configuration for your bucket:\n",
    "response = s3_client.get_bucket_lifecycle_configuration(\n",
    "    Bucket=bucket_name\n",
    ")\n",
    "actual_rules = response['Rules']\n",
    "print(\"Cantidad de reglas actuales: {}\".format(len(actual_rules)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregar la politica actual para no sobrescribirla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = {\n",
    "    'Rules': [\n",
    "        {\n",
    "            'ID': 'Transition tagged objects to S3 Glacier Deep Archive after 3 years',\n",
    "            'Filter': {\n",
    "                    'Tag': {\n",
    "                            'Key': 'TransitionDeepArchive',\n",
    "                            'Value': '1095'\n",
    "                        }\n",
    "            }, \n",
    "            'Status': 'Enabled', \n",
    "            'Transitions': [\n",
    "                {\n",
    "                'Days': 1095,\n",
    "                'StorageClass': 'DEEP_ARCHIVE'\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "    actual_rules[0]  ## Add actual policy\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifecycle configuration applied.\n"
     ]
    }
   ],
   "source": [
    "# Apply the Lifecycle rule configuration:\n",
    "response = s3_client.put_bucket_lifecycle_configuration(\n",
    "    Bucket=bucket_name,\n",
    "    LifecycleConfiguration=json_data\n",
    ")\n",
    "\n",
    "if response['ResponseMetadata']['HTTPStatusCode'] == 200:\n",
    "    print(\"Lifecycle configuration applied.\")\n",
    "else:\n",
    "    print(\"ERROR: Something went wrong.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object uploaded.\n"
     ]
    }
   ],
   "source": [
    "# Upload a object to S3\n",
    "response = s3.Object(bucket_name, 'new-report.png').put(\n",
    "    Body=open('new-report.png', 'rb'),\n",
    "    Tagging='TransitionDeepArchive=1095'\n",
    ")\n",
    "\n",
    "if response['ResponseMetadata']['HTTPStatusCode'] == 200:\n",
    "    print(\"Object uploaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reglas: STANDARD_IA , ONEZONE_IA , INTELLIGENT_TIERING , GLACIER_IR , GLACIER , DEEP_ARCHIVE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c9cdd2fa3b32da9704bd8048bdba085d67219855a318f4adc7f095bb5cfa603b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
